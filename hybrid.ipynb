{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word form -> (morphology, orthography, phonology and multi word expressions)\n",
    "#       properties of the word and characters themselvies. ie. silent letters, sounds like, pre/suffix\n",
    "\n",
    "# PhonologicalEncoder() To-do: phonemes, (phonology)\n",
    "\n",
    "# OrthographicEncoder() To-do: graphemes, (orthography)\n",
    "\n",
    "# MorphologicalEncoder() To-do: morphemes, (morphology)\n",
    "\n",
    "# LexicalEncoder() To-do: lemmas, (lexicon)\n",
    "\n",
    "# SemanticEncoder() done: synonyms, hyponyms/hypernyms,(homographs)\n",
    "        # To-do:  meronyms/holonyms, polysemy (maybe?)\n",
    "\n",
    "# SyntacticEncoder() To-do: word order, word class, (morphology)\n",
    "\n",
    "# PragmaticEncoder() To-do: implicature, presupposition, (conversational implicature)\n",
    "\n",
    "# DiscourseEncoder() To-do: coherence, cohesion, (anaphora)\n",
    "\n",
    "# WorldEncoder() To-do: encyclopedic, (associations)\n",
    "\n",
    "# Combinatorial() To-do: combinations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"Solve today’s NYT Connections game. Here are the instructions for how to play this game:\n",
    "Find groups of four items that share something in common.\n",
    "Category Examples:\n",
    "FISH: Bass, Flounder, Salmon, Trout\n",
    "FIRE ___: Ant, Drill, Island, Opal\n",
    "Categories will always be more specific than\n",
    "‘5-LETTER-WORDS’, ‘NAMES’, or ‘VERBS.’\n",
    "Example 1:\n",
    "Words: [‘DART’, ‘HEM’, ‘PLEAT’, ‘SEAM’,\n",
    "‘CAN’, ‘CURE’, ‘DRY’, ‘FREEZE’, ‘BITE’,\n",
    "‘EDGE’, ‘PUNCH’, ‘SPICE’, ‘CONDO’, ‘HAW’,\n",
    "‘HERO’, ‘LOO’]\n",
    "Groupings:\n",
    "1. Things to sew: [‘DART’, ‘HEM’, ‘PLEAT’,\n",
    "‘SEAM’]\n",
    "2. Ways to preserve food: [‘CAN’, ‘CURE’,\n",
    "‘DRY’, ‘FREEZE’]\n",
    "3. Sharp quality: [‘BITE’, ‘EDGE’, ‘PUNCH’,\n",
    "‘SPICE’]\n",
    "4. Birds minus last letter: [‘CONDO’, ‘HAW’,\n",
    "‘HERO’, ‘LOO’]\n",
    "Example 2:\n",
    "Words: [1COLLECTIVE’, ‘COMMON’, ‘JOINT’,\n",
    "‘MUTUAL’, ‘CLEAR’, ‘DRAIN’, ‘EMPTY’,\n",
    "‘FLUSH’, ‘CIGARETTE’, ‘PENCIL’, ‘TICKET’,\n",
    "‘TOE’, ‘AMERICAN’, ‘FEVER’, ‘LUCID’,\n",
    "‘PIPE’]\n",
    "Groupings:\n",
    "1. Shared: [‘COLLECTIVE’, ‘COMMON’,\n",
    "‘JOINT’, ‘MUTUAL’]\n",
    "2. Rid of contents: [‘CLEAR’, ‘DRAIN’,\n",
    "‘EMPTY’, ‘FLUSH’]\n",
    "3. Associated with “stub”: [‘CIGARETTE’,\n",
    "‘PENCIL’, ‘TICKET’, ‘TOE’]\n",
    "4. __ Dream: [‘AMERICAN’, ‘FEVER’, ‘LU-\n",
    "CID’, ‘PIPE’])\n",
    "Example 3:\n",
    "Words: [‘HANGAR’, ‘RUNWAY’, ‘TARMAC’,\n",
    "‘TERMINAL’, ‘ACTION’, ‘CLAIM’, ‘COM-\n",
    "PLAINT’, ‘LAWSUIT’, ‘BEANBAG’, ‘CLUB’,\n",
    "‘RING’, ‘TORCH’, ‘FOXGLOVE’, ‘GUMSHOE’,\n",
    "‘TURNCOAT’, ‘WINDSOCK’]\n",
    "Groupings:\n",
    "1. Parts of an airport: [‘HANGAR’, ‘RUNWAY’,\n",
    "‘TARMAC’, ‘TERMINAL’]\n",
    "2. Legal terms: [‘ACTION’, ‘CLAIM’, ‘COM-\n",
    "PLAINT’, ‘LAWSUIT’]\n",
    "3. Things a juggler juggles: [‘BEANBAG’,\n",
    "‘CLUB’, ‘RING’, ‘TORCH’]\n",
    "4. Words ending in clothing: [‘FOXGLOVE’,\n",
    "‘GUMSHOE’, ‘TURNCOAT’, ‘WIND-\n",
    "SOCK’]\n",
    "Categories share commonalities:\n",
    "• There are 4 categories of 4 words each\n",
    "• Every word will be in only 1 category\n",
    "• One word will never be in two categories\n",
    "• As the category number increases, the connec-\n",
    "tions between the words and their category\n",
    "become more obscure. Category 1 is the most\n",
    "easy and intuitive and Category 4 is the hard-\n",
    "est\n",
    "• There may be a red herrings (words that seems\n",
    "to belong together but actually are in separate\n",
    "categories)\n",
    "• Category 4 often contains compound words\n",
    "with a common prefix or suffix word\n",
    "• A few other common categories include word\n",
    "and letter patterns, pop culture clues (such as\n",
    "music and movie titles) and fill-in-the-blank\n",
    "phrases\n",
    "You will be given a new example (Example 4) with\n",
    "today’s list of words. First explain your reason\n",
    "for each category and then give your final answer\n",
    "following the structure below (Replace Category 1,\n",
    "2, 3, 4 with their names instead)\n",
    "Groupings:\n",
    "Category1: [word1, word2, word3, word4]\n",
    "Category2: [word5, word6, word7, word8]\n",
    "Category3: [word9, word10, word11, word12]\n",
    "Category4: [word13, word14, word15, word16]\n",
    "Remember that the same word cannot be re-\n",
    "peated across multiple categories, and you need\n",
    "to output 4 categories with 4 distinct words each.\n",
    "Also do not make up words not in the list. This is\n",
    "the most important rule. Please obey\n",
    "Example 4:\n",
    "Words : [InsertGame]\n",
    "Grouping\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example \n",
    "# Words: [‘DART’, ‘HEM’, ‘PLEAT’, ‘SEAM’, ‘CAN’, ‘CURE’, ‘DRY’, ‘FREEZE’, ‘BITE’, ‘EDGE’, ‘PUNCH’, ‘SPICE’, ‘CONDO’, ‘HAW’, ‘HERO’, ‘LOO’]\n",
    "# Groupings:\n",
    "# 1. Things to sew: [‘DART’, ‘HEM’, ‘PLEAT’, ‘SEAM’]\n",
    "# 2. Ways to preserve food: [‘CAN’, ‘CURE’, ‘DRY’, ‘FREEZE’]\n",
    "# 3. Sharp quality: [‘BITE’, ‘EDGE’, ‘PUNCH’, ‘SPICE’]\n",
    "# 4. Birds minus last letter: [‘CONDO’, ‘HAW’, ‘HERO’, ‘LOO’]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/auschra/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import json\n",
    "from itertools import combinations\n",
    "\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('datasets/history.json' , 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "min_similarity = 0.7\n",
    "\n",
    "\n",
    "for entry in history[:1]:\n",
    "    top_pairs = {}\n",
    "    groups = entry['answers']       # entry is a single game\n",
    "    words = [word for group in groups for word in group['members']]    # get all words \n",
    "    words = [word.lower() for word in words]\n",
    "    print(words)\n",
    "\n",
    "    for i, word in enumerate(words):        # iterate over all words\n",
    "        syns1 = wn.synsets(word)            # get all synsets of the word\n",
    "        #print(f\"\\nWord '{word}' has {len(syns1)} synsets\")\n",
    "\n",
    "                \n",
    "        for j, other_word in enumerate(words):   # iterate over all words again\n",
    "                    if i == j:\n",
    "                        continue  # dont compare with same word\n",
    "\n",
    "                    syns2 = wn.synsets(other_word)\n",
    "                    highest_cossim = 0\n",
    "\n",
    "                    # sim between synsets of word and other_word\n",
    "                    for syn1 in syns1:\n",
    "                        for syn2 in syns2:\n",
    "                            cossim = syn1.wup_similarity(syn2)\n",
    "                            if cossim is not None and cossim > highest_cossim:\n",
    "                                highest_cossim = cossim\n",
    "\n",
    "                        # Store pairs with high similarity\n",
    "                        if highest_cossim >= min_similarity:\n",
    "                            top_pairs[(word, other_word)] = highest_cossim\n",
    "                            #print(f\"Pair ({word}, {other_word}) has similarity {highest_cossim}\")\n",
    "\n",
    "\n",
    "    # find groups of 4 words with high similarity\n",
    "    high_similarity_words = list(set([w for pair in top_pairs.keys() for w in pair]))\n",
    "\n",
    "    # check all combinations of 4 words\n",
    "    for word_group in combinations(high_similarity_words, 4):\n",
    "        pairs = list(combinations(word_group, 2))\n",
    "        if all(pair in top_pairs for pair in pairs):\n",
    "            print(\"\\nFound set of 4 highly similar words:\", word_group)\n",
    "            break\n",
    "    else:\n",
    "        print(\"\\nNo set of 4 words found with high similarity across all pairs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Semantics():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.min_similarity = 0.7\n",
    "        self.history = []\n",
    "        self.top_pairs = {}\n",
    "        self.high_similarity_words = []\n",
    "        self.words = []\n",
    "        self.groups = []\n",
    "        self.syns1 = []\n",
    "        self.syns2 = []\n",
    "        self.highest_cossim = 0\n",
    "\n",
    "    def load_history(self, path):\n",
    "        with open(path , 'r') as f:\n",
    "            self.history = json.load(f)\n",
    "\n",
    "    def get_synsets(self, word):\n",
    "        return wn.synsets(word)\n",
    "    \n",
    "    def get_top_pairs(self, word, other_word):\n",
    "        for syn1 in self.syns1:\n",
    "            for syn2 in self.syns2:\n",
    "                cossim = syn1.wup_similarity(syn2)\n",
    "                if cossim is not None and cossim > self.highest_cossim:\n",
    "                    self.highest_cossim = cossim\n",
    "\n",
    "                if self.highest_cossim >= self.min_similarity:\n",
    "                    self.top_pairs[(word, other_word)] = self.highest_cossim\n",
    "\n",
    "    def find_high_similarity_words(self):\n",
    "        self.high_similarity_words = list(set([w for pair in self.top_pairs.keys() for w in pair]))\n",
    "\n",
    "    def find_groups(self):\n",
    "        for word_group in combinations(self.high_similarity_words, 4):\n",
    "            pairs = list(combinations(word_group, 2))\n",
    "            if all(pair in self.top_pairs for pair in pairs):\n",
    "                print(\"\\nFound set of 4 highly similar words:\", word_group)\n",
    "                break\n",
    "        else:\n",
    "            print(\"\\nNo set of 4 words found with high similarity across all pairs.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the class\n",
    "sem = Semantics()\n",
    "sem.load_history('datasets/history.json')\n",
    "\n",
    "for entry in sem.history[:10]:\n",
    "    sem.groups = entry['answers']       # entry is a single game\n",
    "    sem.words = [word for group in sem.groups for word in group['members']]    # get all words \n",
    "    sem.words = [word.lower() for word in sem.words]\n",
    "    print(sem.words)\n",
    "\n",
    "    for i, word in enumerate(sem.words):        # iterate over all words\n",
    "        sem.syns1 = sem.get_synsets(word)            # get all synsets of the word\n",
    "        #print(f\"\\nWord '{word}' has {len(syns1)} synsets\")\n",
    "\n",
    "                \n",
    "        for j, other_word in enumerate(sem.words):   # iterate over all words again\n",
    "                    if i == j:\n",
    "                        continue  # dont compare with same word\n",
    "\n",
    "                    sem.syns2 = sem.get_synsets(other_word)\n",
    "                    sem.highest_cossim = 0\n",
    "\n",
    "                    # sim between synsets of word and other_word\n",
    "                    sem.get_top_pairs(word, other_word)\n",
    "\n",
    "    # Find groups of four words where all pairs have high similarity\n",
    "    sem.find_high_similarity_words()\n",
    "    sem.find_groups()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to /home/auschra/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['HH', 'AH0', 'L', 'OW1'], ['HH', 'EH0', 'L', 'OW1']]\n"
     ]
    }
   ],
   "source": [
    "# phonology test\n",
    "from nltk.corpus import cmudict\n",
    "nltk.download('cmudict')\n",
    "cmu = cmudict.dict()\n",
    "\n",
    "for entry in history[:1]:\n",
    "    groups = entry['answers']       # entry is a single game\n",
    "    words = [word for group in groups for word in group['members']]    # get all words \n",
    "    words = [word.lower() for word in words]\n",
    "    for word in words:\n",
    "        phoneme = cmu[']\n",
    "\n",
    "print(phoneme)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Phonology():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anagram found in group: 94 ['open', 'peon', 'pone', 'nepo']\n"
     ]
    }
   ],
   "source": [
    "class Orthography(): # anagram, palindrome, alliteration\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "# anagram (single use in archive lol)\n",
    "for entry in history:\n",
    "    groups = entry['answers']       # entry is a single game\n",
    "    words = [word for group in groups for word in group['members']]    # get all words \n",
    "    words = [word.lower() for word in words]\n",
    "\n",
    "    an_count = 0\n",
    "    angrams = []\n",
    "\n",
    "\n",
    "    palindrone_count = 0\n",
    "    palindrome = []\n",
    "\n",
    "    # never this simple\n",
    "    # alliteration = []\n",
    "\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        for j, other_word in enumerate(words):\n",
    "            if i == j:\n",
    "                continue\n",
    "            if sorted(word) == sorted(other_word):\n",
    "                an_count += 1\n",
    "                angrams.append(other_word)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "        if an_count == 4:\n",
    "            print(f\"Anagram found in group: {entry['id']} {angrams}\")\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatternMatcher():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "class Morphology():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "\n",
    "class MultiWord():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "class Encyclopedic():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "class Association():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "class Combinations():\n",
    "    def __init__(self):\n",
    "        super().__init__()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectionsEncoder(nn.Module):\n",
    "    def __init__(self, embd=768):\n",
    "        super().__init__()\n",
    "            self.model = 'Llama-3-1-8B'\n",
    "            self.semantic_encoder = Semantics()\n",
    "            self.pattern_matcher = PatternMatcher()\n",
    "            self.morphology = Morphology()\n",
    "            self.orthography = Orthography()\n",
    "            self.phonology = Phonology()\n",
    "            self.multi_word = MultiWord()\n",
    "            self.encyclopedic = Encyclopedic()\n",
    "            self.association = Association()\n",
    "            self.combinations = Combinations()\n",
    "\n",
    "\n",
    "    def relationships(self, words):\n",
    "\n",
    "        prompt=\"\"\"\n",
    "        Consider these words and their semantic relationships.\n",
    "        Look for:\n",
    "        1. Direct category membership\n",
    "        2. Metaphorical connections\n",
    "        3. Word play or double meanings\n",
    "        4. Context-dependent relationships\n",
    "        \"\"\"\n",
    "\n",
    "    return self.combine_evidence(semantic_embeddings, patterns)\n",
    "\n",
    "    # beam search to find optimal groupings\n",
    "    # should 1 shot the problem, don't fall for red herrings\n",
    "\n",
    "    def combine_evidence(self, semantic_embeddings, patterns):\n",
    "        # combine all evidence\n",
    "        return groupings\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BeamSearch(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = ConnectionsEncoder()\n",
    "\n",
    "    # beam search to find optimal groupings\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
