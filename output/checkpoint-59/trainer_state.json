{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 59,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01694915254237288,
      "grad_norm": 3.1580238342285156,
      "learning_rate": 2.9999999999999997e-05,
      "loss": 2.1947,
      "step": 1
    },
    {
      "epoch": 0.03389830508474576,
      "grad_norm": 2.9665374755859375,
      "learning_rate": 5.9999999999999995e-05,
      "loss": 2.203,
      "step": 2
    },
    {
      "epoch": 0.05084745762711865,
      "grad_norm": 2.016535758972168,
      "learning_rate": 8.999999999999999e-05,
      "loss": 2.1836,
      "step": 3
    },
    {
      "epoch": 0.06779661016949153,
      "grad_norm": 1.3293216228485107,
      "learning_rate": 0.00011999999999999999,
      "loss": 2.0009,
      "step": 4
    },
    {
      "epoch": 0.0847457627118644,
      "grad_norm": 1.6255760192871094,
      "learning_rate": 0.00015,
      "loss": 1.9751,
      "step": 5
    },
    {
      "epoch": 0.1016949152542373,
      "grad_norm": 1.6117225885391235,
      "learning_rate": 0.00017999999999999998,
      "loss": 1.8663,
      "step": 6
    },
    {
      "epoch": 0.11864406779661017,
      "grad_norm": 1.6220439672470093,
      "learning_rate": 0.00020999999999999998,
      "loss": 1.7974,
      "step": 7
    },
    {
      "epoch": 0.13559322033898305,
      "grad_norm": 1.506601095199585,
      "learning_rate": 0.00023999999999999998,
      "loss": 1.6505,
      "step": 8
    },
    {
      "epoch": 0.15254237288135594,
      "grad_norm": 1.5972713232040405,
      "learning_rate": 0.00027,
      "loss": 1.5531,
      "step": 9
    },
    {
      "epoch": 0.1694915254237288,
      "grad_norm": 0.9861966371536255,
      "learning_rate": 0.0003,
      "loss": 1.4732,
      "step": 10
    },
    {
      "epoch": 0.1864406779661017,
      "grad_norm": 0.9691340327262878,
      "learning_rate": 0.0002938775510204081,
      "loss": 1.4871,
      "step": 11
    },
    {
      "epoch": 0.2033898305084746,
      "grad_norm": 0.9770352244377136,
      "learning_rate": 0.0002877551020408163,
      "loss": 1.4458,
      "step": 12
    },
    {
      "epoch": 0.22033898305084745,
      "grad_norm": 0.8302508592605591,
      "learning_rate": 0.0002816326530612245,
      "loss": 1.415,
      "step": 13
    },
    {
      "epoch": 0.23728813559322035,
      "grad_norm": 0.9398384690284729,
      "learning_rate": 0.00027551020408163264,
      "loss": 1.3274,
      "step": 14
    },
    {
      "epoch": 0.2542372881355932,
      "grad_norm": 1.2448674440383911,
      "learning_rate": 0.0002693877551020408,
      "loss": 1.3279,
      "step": 15
    },
    {
      "epoch": 0.2711864406779661,
      "grad_norm": 0.9672018885612488,
      "learning_rate": 0.00026326530612244894,
      "loss": 1.2642,
      "step": 16
    },
    {
      "epoch": 0.288135593220339,
      "grad_norm": 1.052605152130127,
      "learning_rate": 0.0002571428571428571,
      "loss": 1.302,
      "step": 17
    },
    {
      "epoch": 0.3050847457627119,
      "grad_norm": 1.156304955482483,
      "learning_rate": 0.0002510204081632653,
      "loss": 1.2652,
      "step": 18
    },
    {
      "epoch": 0.3220338983050847,
      "grad_norm": 1.0360007286071777,
      "learning_rate": 0.00024489795918367346,
      "loss": 1.2525,
      "step": 19
    },
    {
      "epoch": 0.3389830508474576,
      "grad_norm": 0.8986279368400574,
      "learning_rate": 0.0002387755102040816,
      "loss": 1.2254,
      "step": 20
    },
    {
      "epoch": 0.3559322033898305,
      "grad_norm": 0.9487558603286743,
      "learning_rate": 0.00023265306122448976,
      "loss": 1.1975,
      "step": 21
    },
    {
      "epoch": 0.3728813559322034,
      "grad_norm": 0.9182459115982056,
      "learning_rate": 0.00022653061224489791,
      "loss": 1.1928,
      "step": 22
    },
    {
      "epoch": 0.3898305084745763,
      "grad_norm": 1.0680190324783325,
      "learning_rate": 0.00022040816326530612,
      "loss": 1.119,
      "step": 23
    },
    {
      "epoch": 0.4067796610169492,
      "grad_norm": 1.1097345352172852,
      "learning_rate": 0.00021428571428571427,
      "loss": 1.1493,
      "step": 24
    },
    {
      "epoch": 0.423728813559322,
      "grad_norm": 1.1144570112228394,
      "learning_rate": 0.00020816326530612243,
      "loss": 1.1242,
      "step": 25
    },
    {
      "epoch": 0.4406779661016949,
      "grad_norm": 1.013004183769226,
      "learning_rate": 0.00020204081632653058,
      "loss": 1.0866,
      "step": 26
    },
    {
      "epoch": 0.4576271186440678,
      "grad_norm": 1.5739003419876099,
      "learning_rate": 0.00019591836734693873,
      "loss": 1.085,
      "step": 27
    },
    {
      "epoch": 0.4745762711864407,
      "grad_norm": 1.1460976600646973,
      "learning_rate": 0.00018979591836734694,
      "loss": 1.0464,
      "step": 28
    },
    {
      "epoch": 0.4915254237288136,
      "grad_norm": 1.2370675802230835,
      "learning_rate": 0.0001836734693877551,
      "loss": 1.0438,
      "step": 29
    },
    {
      "epoch": 0.5084745762711864,
      "grad_norm": 1.1111936569213867,
      "learning_rate": 0.00017755102040816325,
      "loss": 1.0354,
      "step": 30
    },
    {
      "epoch": 0.5254237288135594,
      "grad_norm": 1.1148709058761597,
      "learning_rate": 0.0001714285714285714,
      "loss": 1.0122,
      "step": 31
    },
    {
      "epoch": 0.5423728813559322,
      "grad_norm": 1.2572286128997803,
      "learning_rate": 0.00016530612244897955,
      "loss": 0.9989,
      "step": 32
    },
    {
      "epoch": 0.559322033898305,
      "grad_norm": 1.126613736152649,
      "learning_rate": 0.00015918367346938776,
      "loss": 0.9903,
      "step": 33
    },
    {
      "epoch": 0.576271186440678,
      "grad_norm": 1.1675872802734375,
      "learning_rate": 0.0001530612244897959,
      "loss": 0.911,
      "step": 34
    },
    {
      "epoch": 0.5932203389830508,
      "grad_norm": 1.2628892660140991,
      "learning_rate": 0.00014693877551020406,
      "loss": 0.8851,
      "step": 35
    },
    {
      "epoch": 0.6101694915254238,
      "grad_norm": 1.5132040977478027,
      "learning_rate": 0.00014081632653061224,
      "loss": 0.9158,
      "step": 36
    },
    {
      "epoch": 0.6271186440677966,
      "grad_norm": 1.3147333860397339,
      "learning_rate": 0.0001346938775510204,
      "loss": 0.8785,
      "step": 37
    },
    {
      "epoch": 0.6440677966101694,
      "grad_norm": 1.251460313796997,
      "learning_rate": 0.00012857142857142855,
      "loss": 0.8327,
      "step": 38
    },
    {
      "epoch": 0.6610169491525424,
      "grad_norm": 1.222895860671997,
      "learning_rate": 0.00012244897959183673,
      "loss": 0.8199,
      "step": 39
    },
    {
      "epoch": 0.6779661016949152,
      "grad_norm": 1.5010488033294678,
      "learning_rate": 0.00011632653061224488,
      "loss": 0.8493,
      "step": 40
    },
    {
      "epoch": 0.6949152542372882,
      "grad_norm": 1.403039813041687,
      "learning_rate": 0.00011020408163265306,
      "loss": 0.8315,
      "step": 41
    },
    {
      "epoch": 0.711864406779661,
      "grad_norm": 1.307166576385498,
      "learning_rate": 0.00010408163265306121,
      "loss": 0.7658,
      "step": 42
    },
    {
      "epoch": 0.7288135593220338,
      "grad_norm": 1.2691479921340942,
      "learning_rate": 9.795918367346937e-05,
      "loss": 0.7681,
      "step": 43
    },
    {
      "epoch": 0.7457627118644068,
      "grad_norm": 1.3397983312606812,
      "learning_rate": 9.183673469387755e-05,
      "loss": 0.7484,
      "step": 44
    },
    {
      "epoch": 0.7627118644067796,
      "grad_norm": 1.2979655265808105,
      "learning_rate": 8.57142857142857e-05,
      "loss": 0.7246,
      "step": 45
    },
    {
      "epoch": 0.7796610169491526,
      "grad_norm": 1.4601085186004639,
      "learning_rate": 7.959183673469388e-05,
      "loss": 0.74,
      "step": 46
    },
    {
      "epoch": 0.7966101694915254,
      "grad_norm": 1.3908170461654663,
      "learning_rate": 7.346938775510203e-05,
      "loss": 0.726,
      "step": 47
    },
    {
      "epoch": 0.8135593220338984,
      "grad_norm": 1.3731783628463745,
      "learning_rate": 6.73469387755102e-05,
      "loss": 0.6914,
      "step": 48
    },
    {
      "epoch": 0.8305084745762712,
      "grad_norm": 1.2934080362319946,
      "learning_rate": 6.122448979591836e-05,
      "loss": 0.7005,
      "step": 49
    },
    {
      "epoch": 0.847457627118644,
      "grad_norm": 1.3213578462600708,
      "learning_rate": 5.510204081632653e-05,
      "loss": 0.6681,
      "step": 50
    },
    {
      "epoch": 0.864406779661017,
      "grad_norm": 1.3100751638412476,
      "learning_rate": 4.897959183673468e-05,
      "loss": 0.6963,
      "step": 51
    },
    {
      "epoch": 0.8813559322033898,
      "grad_norm": 1.3655201196670532,
      "learning_rate": 4.285714285714285e-05,
      "loss": 0.6572,
      "step": 52
    },
    {
      "epoch": 0.8983050847457628,
      "grad_norm": 1.3676999807357788,
      "learning_rate": 3.6734693877551016e-05,
      "loss": 0.6658,
      "step": 53
    },
    {
      "epoch": 0.9152542372881356,
      "grad_norm": 1.3254294395446777,
      "learning_rate": 3.061224489795918e-05,
      "loss": 0.6289,
      "step": 54
    },
    {
      "epoch": 0.9322033898305084,
      "grad_norm": 1.2778366804122925,
      "learning_rate": 2.448979591836734e-05,
      "loss": 0.6449,
      "step": 55
    },
    {
      "epoch": 0.9491525423728814,
      "grad_norm": 1.455427885055542,
      "learning_rate": 1.8367346938775508e-05,
      "loss": 0.6735,
      "step": 56
    },
    {
      "epoch": 0.9661016949152542,
      "grad_norm": 1.3254414796829224,
      "learning_rate": 1.224489795918367e-05,
      "loss": 0.6395,
      "step": 57
    },
    {
      "epoch": 0.9830508474576272,
      "grad_norm": 1.2768852710723877,
      "learning_rate": 6.122448979591835e-06,
      "loss": 0.6369,
      "step": 58
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.3656067848205566,
      "learning_rate": 0.0,
      "loss": 0.627,
      "step": 59
    }
  ],
  "logging_steps": 1,
  "max_steps": 59,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.177861902191821e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
